{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='justtemp (6).png' width='75%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(6,2,16)\n",
    "y = np.random.randn(6,2,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.36470437,  0.87200251, -1.18250177,  0.44407913,  1.43573175,\n",
       "         -0.96392373,  0.80048372,  0.37646168,  0.50118034, -0.54184833,\n",
       "          0.56504924, -1.08860538, -2.25951443,  0.61756878, -0.67466977,\n",
       "         -1.01981043],\n",
       "        [ 1.54401809, -0.00483111,  2.16767851, -0.57002522,  0.16628122,\n",
       "         -0.45750552, -0.92246314, -1.56876512, -1.6414432 , -0.37762223,\n",
       "          0.88806984, -0.37810634,  0.52033298,  0.74484429, -0.56735781,\n",
       "         -0.27987345]]),\n",
       " array([[ 1.72887491, -0.30841473, -0.6640174 ,  0.98275548, -0.50554817,\n",
       "         -0.71441   ,  0.82188782,  0.44255599,  0.31975046, -1.47244758,\n",
       "         -1.04747443, -0.07611002,  1.79969344, -1.35069793, -0.36791814,\n",
       "         -0.70841665],\n",
       "        [ 1.4404599 ,  1.29851254, -0.96777917,  1.33310005,  1.51382273,\n",
       "         -0.56265939, -0.58545693,  2.76027713,  1.65141094, -0.72207618,\n",
       "          0.01303044,  0.53231669,  0.01865763, -0.03647782,  0.39357133,\n",
       "         -1.07791898]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsQ = np.random.randn(2,16)\n",
    "weightsK = np.random.randn(2,16)\n",
    "weightsV = np.random.randn(2,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 2, 2), (6, 2, 2), (6, 2, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.matmul(weightsQ, x[:,:,:,None]).squeeze(3)\n",
    "K = np.matmul(weightsK, x[:,:,:,None]).squeeze(3)\n",
    "V = np.matmul(weightsV, x[:,:,:,None]).squeeze(3)\n",
    "Q.shape, K.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, byline=True):\n",
    "    if byline:\n",
    "        x = np.clip(x, 1e-8, 1 - 1e-8)\n",
    "        for i in range(x.shape[0]):\n",
    "            x[i] = np.exp(x[i]) / (np.sum(np.exp(x[i])))\n",
    "\n",
    "        return x\n",
    "\n",
    "    x = np.clip(x, 1e-8, 1 - 1e-8)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "\n",
    "            x[i, j] = np.exp(x[i, j]) / (np.sum(np.exp(x[i, j])))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QK = softmax(np.matmul(Q, K.reshape(K.shape[0], K.shape[2], Q.shape[1])) / Q.shape[1])\n",
    "\n",
    "QK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.matmul(QK, V)\n",
    "\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(weightsQ, weightsK, weightsV, x, masked=False, encoded=None, back_prop=False):\n",
    "\n",
    "    Q = np.matmul(weightsQ, x[:,:,:,None]).squeeze(3)\n",
    "\n",
    "    x = encoded if encoded is not None else x\n",
    "\n",
    "    K = np.matmul(weightsK, x[:,:,:,None]).squeeze(3)\n",
    "    V = np.matmul(weightsV, x[:,:,:,None]).squeeze(3)\n",
    "\n",
    "    QK = np.matmul(Q, K.reshape(K.shape[0], K.shape[2], K.shape[1])) / Q.shape[1]\n",
    "    \n",
    "    if masked:\n",
    "        for i in range(1, QK.shape[2]):\n",
    "            QK[:i, i] = -np.inf\n",
    "\n",
    "    Qk = softmax(QK)\n",
    "\n",
    "    res = np.matmul(Qk, V)\n",
    "\n",
    "    if back_prop:\n",
    "        return Qk, Q, K, V, QK\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead(x, heads, weightsQ=None, weightsK=None, weightsV=None, weightO=None, masked=False, encoded=None):\n",
    "    dk = int(x.shape[2]/heads)\n",
    "    should_add = False\n",
    "\n",
    "    if weightsQ is None:\n",
    "        weightsQ = []\n",
    "        weightsK = []\n",
    "        weightsV = []\n",
    "\n",
    "        should_add = True\n",
    "\n",
    "    for i in range(heads):\n",
    "            \n",
    "        if should_add:\n",
    "            weightsQ.append(np.random.randn(dk, x.shape[2]) * 0.01)\n",
    "            weightsK.append(np.random.randn(dk, x.shape[2]) * 0.01)\n",
    "            weightsV.append(np.random.randn(dk, x.shape[2]) * 0.01)\n",
    "\n",
    "        if i == 0:\n",
    "            res = attention(weightsQ[i], weightsK[i], weightsV[i], x, masked, encoded)\n",
    "            continue\n",
    "\n",
    "        res = np.concatenate((res, attention(weightsQ[i], weightsK[i], weightsV[i], x, masked)), axis=2)\n",
    "\n",
    "    if weightO is None:\n",
    "        weightO = np.random.randn(heads*dk, x.shape[2])\n",
    "\n",
    "    result = np.matmul(weightO, res[:,:,:,None]).squeeze(axis=3)\n",
    "\n",
    "    if should_add:\n",
    "        return result, weightsQ, weightsK, weightsV, weightO, res\n",
    "    \n",
    "    return result, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res,_,_,_,_,_ = multihead(x, 8)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(x):\n",
    "    for pos in range(x.shape[1]):\n",
    "        if pos%2 == 0:\n",
    "            x[:, pos] += np.sin(pos/10000**(2*pos/2 / x.shape[1]))\n",
    "        else:\n",
    "            x[:, pos] += np.cos(pos/10000**(2*(pos/2 -1) / x.shape[1]))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36470437,  0.87200251, -1.18250177,  0.44407913,  1.43573175,\n",
       "        -0.96392373,  0.80048372,  0.37646168,  0.50118034, -0.54184833,\n",
       "         0.56504924, -1.08860538, -2.25951443,  0.61756878, -0.67466977,\n",
       "        -1.01981043],\n",
       "       [ 1.54401809, -0.00483111,  2.16767851, -0.57002522,  0.16628122,\n",
       "        -0.45750552, -0.92246314, -1.56876512, -1.6414432 , -0.37762223,\n",
       "         0.88806984, -0.37810634,  0.52033298,  0.74484429, -0.56735781,\n",
       "        -0.27987345]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36470437,  0.87200251, -1.18250177,  0.44407913,  1.43573175,\n",
       "        -0.96392373,  0.80048372,  0.37646168,  0.50118034, -0.54184833,\n",
       "         0.56504924, -1.08860538, -2.25951443,  0.61756878, -0.67466977,\n",
       "        -1.01981043],\n",
       "       [ 2.40633697,  0.85748776,  3.02999738,  0.29229365,  1.0286001 ,\n",
       "         0.40481335, -0.06014426, -0.70644625, -0.77912433,  0.48469664,\n",
       "         1.75038871,  0.48421253,  1.38265185,  1.60716316,  0.29496106,\n",
       "         0.58244542]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, gamma, beta):\n",
    "    return gamma*(x-np.mean(x, axis=(0,1)))/np.std(x, axis=(0,1)) + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5396290562691443, 0.9247159537163941)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(norm(x, 1, 0)[0][0]), np.std(norm(x, 1, 0)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    x = positional_encoding(x)\n",
    "    \n",
    "    mha, weightsQ, weightsK, weightsV, weightO, middle = multihead(x, 8)\n",
    "    x += mha\n",
    "\n",
    "\n",
    "    gamma = np.random.randn(x.shape[2]) * 0.01\n",
    "    beta = np.random.randn(1) * 0.01\n",
    "    x = norm(x, gamma, beta)\n",
    "\n",
    "    weight1 = np.random.randn(x.shape[2]*4, x.shape[2]) * 0.01\n",
    "    bias1 = np.random.randn(2,x.shape[2]*4) * 0.01\n",
    "    weight2 = np.random.randn(x.shape[2], x.shape[2]*4) * 0.01\n",
    "    bias2 = np.random.randn(2,x.shape[2]) * 0.01\n",
    "\n",
    "    Z1 = np.matmul(weight1, x[:,:,:,None]).squeeze(3) + bias1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.matmul(weight2, A1[:,:,:,None]).squeeze(3) + bias2\n",
    "\n",
    "    return Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x, encoded):\n",
    "    x = positional_encoding(x)\n",
    "\n",
    "    mha, weightsQ, weightsK, weightsV, weightO, middle = multihead(x, 8, masked=True)\n",
    "    x += mha\n",
    "\n",
    "    gamma1 = np.random.randn(x.shape[2]) * 0.01\n",
    "    beta1 = np.random.randn(1) * 0.01\n",
    "    x = norm(x, gamma1, beta1)\n",
    "\n",
    "    mha2, weightsQ2, weightsK2, weightsV2, weightO2, middle2 = multihead(x, 8, encoded=encoded)\n",
    "    x += mha2\n",
    "\n",
    "    gamma2 = np.random.randn(x.shape[2]) * 0.01\n",
    "    beta2 = np.random.randn(1)     * 0.01\n",
    "    x = norm(x, gamma1, beta1)\n",
    "\n",
    "    weight1 = np.random.randn(x.shape[2]*4, x.shape[2]) * 0.01\n",
    "    bias1 = np.random.randn(2,x.shape[2]*4) * 0.01\n",
    "    weight2 = np.random.randn(x.shape[2], x.shape[2]*4) * 0.01\n",
    "    bias2 = np.random.randn(2,x.shape[2]) * 0.01\n",
    "\n",
    "    Z1 = np.matmul(weight1, x[:,:,:,None]).squeeze(3) + bias1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.matmul(weight2, A1[:,:,:,None]).squeeze(3) + bias2\n",
    "\n",
    "    return Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(y, encoder(x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(x):\n",
    "    weight1 = np.random.randn(16, x.shape[2]) * 0.01\n",
    "    bias1 = np.random.randn(2,16) * 0.01\n",
    "\n",
    "    Z1 = np.matmul(weight1, x[:,:,:,None]).squeeze(3) + bias1\n",
    "    A1 = softmax(Z1, False)\n",
    "\n",
    "    return A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(final(decoder(y, encoder(x)))[0,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackProp\n",
    "<img style='width:75%' src='justtemp (7).png'/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Skip Connection $$\\cfrac{\\delta L}{\\delta x} = \\cfrac{\\delta L}{\\delta H}\\cfrac{\\delta H}{\\delta x} = \\cfrac{\\delta L}{\\delta H} ( \\cfrac{\\delta F}{\\delta x} + 1 ) = \\cfrac{\\delta L}{\\delta H}\\cfrac{\\delta F}{\\delta x} + \\cfrac{\\delta L}{\\delta H}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_hat):\n",
    "    return np.mean((y - y_hat)**2, axis=(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00093971, 10.0489294 ],\n",
       "       [ 1.14874611,  7.11292786],\n",
       "       [ 0.29201138,  7.48690935],\n",
       "       [ 0.71747214,  6.77709729],\n",
       "       [ 1.37684997,  6.04899903],\n",
       "       [ 0.78773674,  5.5905806 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(final(decoder(y, encoder(x).reshape(x.shape))).reshape(y.shape), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y = [1, 2, 16]):\n",
    "\n",
    "    one_hot_matrix = np.zeros((y))\n",
    "\n",
    "    for i in range(y[0]):\n",
    "        for j in range(y[1]):\n",
    "            one_hot_matrix[i,j,np.random.randint(y[2])] = 1\n",
    "\n",
    "    return one_hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_true = np.random.randn(1,2,16)\n",
    "y_true = one_hot([1, 2, 16])\n",
    "heads = 8\n",
    "dk = int(x_true.shape[2]/heads)\n",
    "\n",
    "x = positional_encoding(x_true)\n",
    "\n",
    "mha, weightsQ, weightsK, weightsV, weightO, middle = multihead(x, heads)\n",
    "# mha = x\n",
    "x1 = x + mha\n",
    "\n",
    "gamma = np.random.randn(x.shape[2]) * 0.01\n",
    "beta = np.random.randn(1) * 0.01\n",
    "x2 = norm(x1, gamma, beta)\n",
    "\n",
    "# x2 = x1\n",
    "\n",
    "weight1 = np.random.randn(x.shape[2]*4, x.shape[2]) * 0.01\n",
    "bias1 = np.random.randn(x.shape[1],x.shape[2]*4) * 0.01\n",
    "weight2 = np.random.randn(x.shape[2], x.shape[2]*4) * 0.01\n",
    "bias2 = np.random.randn(x.shape[1],x.shape[2]) * 0.01\n",
    "\n",
    "Z1 = np.matmul(weight1, x2[:,:,:,None]).squeeze(3) + bias1\n",
    "A1 = relu(Z1)\n",
    "encoded = np.matmul(weight2, A1[:,:,:,None]).squeeze(3) + bias2\n",
    "\n",
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = positional_encoding(x_true)\n",
    "\n",
    "Dmha, DweightsQ, DweightsK, DweightsV, DweightO, Dmiddle = multihead(x, heads, masked=True)\n",
    "\n",
    "# Dmha = x\n",
    "x3 = x + Dmha\n",
    "\n",
    "Dgamma1 = np.random.randn(x.shape[2]) * 0.01\n",
    "Dbeta1 = np.random.randn(1) * 0.01\n",
    "x4 = norm(x3, Dgamma1, Dbeta1)\n",
    "\n",
    "# x4 = x3\n",
    "\n",
    "Dmha2, DweightsQ2, DweightsK2, DweightsV2, DweightO2, Dmiddle2 = multihead(x4, heads, encoded=encoded)\n",
    "\n",
    "# Dmha2 = x4\n",
    "x5 = x4 + Dmha2\n",
    "\n",
    "Dgamma2 = np.random.randn(x.shape[2]) * 0.01\n",
    "Dbeta2 = np.random.randn(1)    * 0.01\n",
    "x6 = norm(x5, Dgamma2, Dbeta2)\n",
    "\n",
    "# x6 = x5\n",
    "\n",
    "Dweight1 = np.random.randn(x.shape[2]*4, x.shape[2]) * 0.01\n",
    "Dbias1 = np.random.randn(x.shape[1],x.shape[2]*4) * 0.01\n",
    "Dweight2 = np.random.randn(x.shape[2], x.shape[2]*4) * 0.01\n",
    "Dbias2 = np.random.randn(x.shape[1],x.shape[2]) * 0.01\n",
    "\n",
    "DZ1 = np.matmul(Dweight1, x6[:,:,:,None]).squeeze(3) + Dbias1\n",
    "DA1 = relu(Z1)\n",
    "Decoded = np.matmul(Dweight2, DA1[:,:,:,None]).squeeze(3) + Dbias2\n",
    "Decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 16)\n"
     ]
    }
   ],
   "source": [
    "fweight1 = np.random.randn(16, Decoded.shape[2]) * 0.01\n",
    "fbias1 = np.random.randn(x.shape[1],16) * 0.01\n",
    "\n",
    "fZ1 = np.matmul(fweight1, Decoded[:,:,:,None]).squeeze(3) + fbias1\n",
    "fA1 = softmax(fZ1, False)\n",
    "\n",
    "print(fA1.shape)\n",
    "\n",
    "loss = mse(fA1, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_back(dout, x, gamma):\n",
    "\n",
    "    n = x.shape[0]\n",
    "\n",
    "    x_hat = (x5-np.mean(x5, axis=(0,1)))/np.std(x5, axis=(0,1))\n",
    "    std = np.std(x5, axis=(0,1))\n",
    "    mean = np.mean(x5, axis=(0,1))\n",
    "\n",
    "    dgamma = np.mean(dout * x_hat, axis=(0,1))\n",
    "    dbeta = np.mean(dout, axis=(0,1,2)).reshape(1)\n",
    "\n",
    "    dx_hat = dout * gamma\n",
    "\n",
    "    dstd = 1/std * np.sum(dx_hat * (mean-x5), axis=(0,1))\n",
    "    dmean = -1/std * np.sum(dx_hat, axis=(0,1)) + 1/(n * std) * np.sum(mean-x5, axis=(0,1))\n",
    "\n",
    "    dx = dx_hat * 1/std + dmean * 1/n + dstd * 1/(n*std) * (x-mean)\n",
    "\n",
    "    return dx, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_back(dout, x, weight, for_relu=None):\n",
    "    dweight = (1/x.shape[1]) * np.matmul(np.mean(dout, axis=0).T, np.mean(x, axis=0))\n",
    "    dbias = (1/x.shape[1]) * np.mean(dout, axis=0)\n",
    "\n",
    "    dx = np.matmul(dout, weight)\n",
    "    \n",
    "    if for_relu is not None:\n",
    "        dx = np.where(for_relu > 0, dx, 1e-8)\n",
    "        dx[dx <= 0] = 1e-8\n",
    "    \n",
    "        return dx, dweight, dbias\n",
    "    \n",
    "    return dx, dweight, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mha_back(dout, x, weightO, weightsQ, weightsK, weightsV, middle, heads=8, masked=False, encoded=None):\n",
    "    dweightO = np.matmul(np.mean(dout, axis=0).T, np.mean(middle, axis=0))\n",
    "    dmiddles = np.matmul(dout, weightO)\n",
    "\n",
    "    dweightsQ = []\n",
    "    dweightsK = []\n",
    "    dweightsV = []\n",
    "\n",
    "    for i in range(heads):\n",
    "        dmiddle = dmiddles[:,:,dk*i:dk*(i+1)]\n",
    "        weightQ = weightsQ[i]\n",
    "        weightK = weightsK[i]\n",
    "        weightV = weightsV[i]\n",
    "\n",
    "        Qk, Q, K, V, QK = attention(weightQ, weightK, weightV, x, masked=masked, encoded=encoded, back_prop=True)\n",
    "\n",
    "        dV = np.matmul(Qk, dmiddle)\n",
    "        dQk = np.matmul(V, dmiddle)\n",
    "\n",
    "        dQK = dQk * (softmax(QK) - softmax(QK)**2)\n",
    "\n",
    "        dK = np.matmul(dQK, Q / Q.shape[1])\n",
    "        dQ = np.matmul(dQK, K / K.shape[1])\n",
    "\n",
    "        dweightQ = np.matmul(np.mean(dQ, axis=0).T, np.mean(x, axis=0))\n",
    "        dweightK = np.matmul(np.mean(dK, axis=0).T, np.mean(x, axis=0))\n",
    "        dweightV = np.matmul(np.mean(dV, axis=0).T, np.mean(x, axis=0))\n",
    "\n",
    "        dweightsQ.append(dweightQ)\n",
    "        dweightsK.append(dweightK)\n",
    "        dweightsV.append(dweightV)\n",
    "\n",
    "        if i == 0:\n",
    "            dx = np.matmul(dQ, weightQ)\n",
    "            dencoded = np.matmul(dK, weightK)\n",
    "            dencoded += np.matmul(dV, weightV)\n",
    "        else:\n",
    "            dx += np.matmul(dQ, weightQ)\n",
    "            dencoded += np.matmul(dK, weightK)\n",
    "            dencoded += np.matmul(dV, weightV)\n",
    "    \n",
    "    if encoded is not None:\n",
    "        return dx, dweightO, dweightsQ, dweightsK, dweightsV, dencoded\n",
    "    \n",
    "    dx += dencoded\n",
    "\n",
    "    return dx, dweightO, dweightsQ, dweightsK, dweightsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss before:  0.05861015427591424 \n",
      "\n",
      "answer before:  [[ 4 14]]\n",
      "target: [[0 9]] \n",
      "\n",
      "0.058570903577835384\n",
      "\n",
      "0.058528723822341214\n",
      "\n",
      "0.05848617932016602\n",
      "\n",
      "0.05844330847726789\n",
      "\n",
      "0.05840007064059044\n",
      "\n",
      "0.058356484814388945\n",
      "\n",
      "0.058312536453926506\n",
      "\n",
      "0.05826818115021699\n",
      "\n",
      "0.058223413761990236\n",
      "\n",
      "0.05817822907010423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('loss before: ', np.mean(loss), '\\n')\n",
    "print('answer before: ', np.argmax(fA1, axis=(2)))\n",
    "print('target:', np.argmax(y_true, axis=(2)), '\\n')\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    n = y_true.shape[0]\n",
    "\n",
    "    dfA1 = -2/n * (y_true-fA1.reshape(y_true.shape))\n",
    "    dfZ1 = dfA1 * (softmax(fZ1, False) - softmax(fZ1, False)**2)\n",
    "\n",
    "    # fc\n",
    "    \n",
    "    dDecoded, dfweight1, dfbias1 = fc_back(dfZ1, Decoded, fweight1, for_relu=fZ1)\n",
    "\n",
    "    # fc\n",
    "\n",
    "    dDZ1, dDweight2, dDbias2 = fc_back(dDecoded, DA1, Dweight2)\n",
    "\n",
    "    # fc\n",
    "\n",
    "    dx6, dDweight1, dDbias1 = fc_back(dDZ1, x6, Dweight1)\n",
    "\n",
    "    # norm\n",
    "\n",
    "    dx5, dDgamma2, dDbeta2 = norm_back(dx6, x5, Dgamma2)\n",
    "\n",
    "    # dx5 = dx6\n",
    "\n",
    "    # mha\n",
    "\n",
    "    dx4, dDweightO2, dDweightsQ2, dDweightsK2, dDweightsV2, Dencoded = mha_back(dx5, x4, DweightO2, DweightsQ2, DweightsK2, DweightsV2, Dmiddle2, encoded=encoded)\n",
    "    # dx4 = dx5\n",
    "\n",
    "    # skip\n",
    "\n",
    "    dx4 = dx5*dx4 + dx5\n",
    "\n",
    "    # norm\n",
    "\n",
    "    dx3, dDgamma1, dDbeta1 = norm_back(dx4, x3, Dgamma1)\n",
    "\n",
    "    # dx3 = dx4\n",
    "\n",
    "    # mha \n",
    "\n",
    "    dx, dDweightO1, dDweightsQ1, dDweightsK1, dDweightsV1 = mha_back(dx3, x, DweightO, DweightsQ, DweightsK, DweightsV, Dmiddle, masked=True)\n",
    "\n",
    "    # dx = dx3\n",
    "\n",
    "    # skip\n",
    "\n",
    "    dx = dx3*dx + dx3\n",
    "\n",
    "    # fc\n",
    "\n",
    "    dZ1, dweight2, dbias2 = fc_back(dx, A1, weight2, for_relu=Z1)\n",
    "\n",
    "    # fc\n",
    "\n",
    "    dx2, dweight1, dbias1 = fc_back(dZ1, x2, weight1)\n",
    "\n",
    "    # norm\n",
    "\n",
    "    dx1, dgamma1, dbeta1 = norm_back(dx2, x1, gamma)\n",
    "\n",
    "    # dx1 = dx2\n",
    "\n",
    "    # mha\n",
    "\n",
    "    dx, dweightO, dweightsQ, dweightsK, dweightsV = mha_back(dx1, x, weightO, weightsQ, weightsK, weightsV, middle)\n",
    "\n",
    "    dx = dx1\n",
    "\n",
    "    learning_rate = 0.1\n",
    "\n",
    "    weightO -= learning_rate * dweightO\n",
    "\n",
    "    for i, j in enumerate(dweightsQ):\n",
    "        weightsQ[i] -= learning_rate * j\n",
    "        \n",
    "    for i, j in enumerate(dweightsK):\n",
    "        weightsK[i] -= learning_rate * j\n",
    "        \n",
    "    for i, j in enumerate(dweightsV):\n",
    "        weightsV[i] -= learning_rate * j\n",
    "\n",
    "    gamma -= learning_rate * dgamma1\n",
    "    beta -= learning_rate * dbeta1\n",
    "\n",
    "    weight1 -= learning_rate * dweight1\n",
    "    bias1 -= learning_rate * dbias1\n",
    "    weight2 -= learning_rate * dweight2\n",
    "    bias2 -= learning_rate * dbias2\n",
    "\n",
    "    DweightO -= learning_rate * dDweightO1\n",
    "\n",
    "    for i, j in enumerate(dDweightsQ1):\n",
    "        DweightsQ[i] -= learning_rate * j\n",
    "        \n",
    "    for i, j in enumerate(dDweightsK1):\n",
    "        DweightsK[i] -= learning_rate * j\n",
    "        \n",
    "    for i, j in enumerate(dDweightsV1):\n",
    "        DweightsV[i] -= learning_rate * j\n",
    "\n",
    "    Dgamma1 -= learning_rate * dDgamma1\n",
    "    Dbeta1 -= learning_rate * dDbeta1\n",
    "\n",
    "    DweightO2 -= learning_rate * dDweightO2\n",
    "\n",
    "    for i, j in enumerate(dDweightsQ2):\n",
    "        DweightsQ[i] -= learning_rate * j\n",
    "        \n",
    "    for i, j in enumerate(dDweightsK2):\n",
    "        DweightsK[i] -= learning_rate * j\n",
    "        \n",
    "    for i, j in enumerate(dDweightsV2):\n",
    "        DweightsV[i] -= learning_rate * j\n",
    "\n",
    "    Dgamma2 -= learning_rate * dDgamma2\n",
    "    Dbeta2 -= learning_rate * dDbeta2\n",
    "\n",
    "    dweight1 -= learning_rate * dDweight1\n",
    "    dbias1 -= learning_rate * dDbias1\n",
    "    dweight2 -= learning_rate * dDweight2\n",
    "    dbias2 -= learning_rate * dDbias2\n",
    "\n",
    "    fweight1 -= learning_rate * dfweight1\n",
    "    fbias1 -= learning_rate * dfbias1\n",
    "\n",
    "\n",
    "    x = positional_encoding(x_true)\n",
    "\n",
    "    mha, middle = multihead(x, heads, weightsQ, weightsK, weightsV, weightO)\n",
    "    # mha = x\n",
    "    x1 = x + mha\n",
    "\n",
    "    x2 = norm(x1, gamma, beta)\n",
    "\n",
    "    # x2 = x1\n",
    "\n",
    "    Z1 = np.matmul(weight1, x2[:,:,:,None]).squeeze(3) + bias1\n",
    "    A1 = relu(Z1)\n",
    "    encoded = np.matmul(weight2, A1[:,:,:,None]).squeeze(3) + bias2\n",
    "\n",
    "    x = positional_encoding(x_true)\n",
    "\n",
    "    Dmha, Dmiddle = multihead(x, heads, DweightsQ, DweightsK, DweightsV, DweightO, masked=True)\n",
    "    # Dmha = x\n",
    "    x3 = x + Dmha\n",
    "\n",
    "    x4 = norm(x3, Dgamma1, Dbeta1)\n",
    "\n",
    "    # x4 = x3\n",
    "\n",
    "    Dmha2, Dmiddle2 = multihead(x4, heads, DweightsQ2, DweightsK2, DweightsV2, DweightO2, encoded=encoded)\n",
    "\n",
    "    # Dmha2 = x4\n",
    "    x5 = x4 + Dmha2\n",
    "\n",
    "    x6 = norm(x5, Dgamma2, Dbeta2)\n",
    "\n",
    "    # x6 = x5\n",
    "\n",
    "\n",
    "    DZ1 = np.matmul(Dweight1, x6[:,:,:,None]).squeeze(3) + Dbias1\n",
    "    DA1 = relu(Z1)\n",
    "    Decoded = np.matmul(Dweight2, DA1[:,:,:,None]).squeeze(3) + Dbias2\n",
    "\n",
    "\n",
    "    fZ1 = np.matmul(fweight1, Decoded[:,:,:,None]).squeeze(3) + fbias1\n",
    "    fA1 = softmax(fZ1, False)\n",
    "\n",
    "    print(np.mean(mse(fA1, y_true)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 9]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(fA1, axis=(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 9]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_true, axis=(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 16), (16, 16))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dweightO.shape, weightO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 16), (1, 2, 16))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dencoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dencoded\u001b[39m.\u001b[39mshape, encoded\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dencoded' is not defined"
     ]
    }
   ],
   "source": [
    "dencoded.shape, encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 16), (1, 2, 16))"
      ]
     },
     "execution_count": 5062,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx4.shape, x4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 16), (2, 16))"
      ]
     },
     "execution_count": 5063,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddweightsQ2[0].shape, dweightsQ2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 16), (2, 16))"
      ]
     },
     "execution_count": 5064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddweightsV2[0].shape, dweightsV2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 16), (2, 16))"
      ]
     },
     "execution_count": 5065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddweightsK2[0].shape, dweightsK2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 16), (16, 16))"
      ]
     },
     "execution_count": 5066,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddweightO2.shape, dweightO2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 16), (1, 2, 16))"
      ]
     },
     "execution_count": 5067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx5.shape, x5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), (1,))"
      ]
     },
     "execution_count": 5068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddbeta2.shape, dbeta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16,), (16,))"
      ]
     },
     "execution_count": 5069,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddgamma2.shape, dgamma2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 16), (2, 64), (64, 16), (2, 64))"
      ]
     },
     "execution_count": 5070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddweight1.shape, ddbias1.shape, dweight1.shape, dbias1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 64), (1, 2, 64))"
      ]
     },
     "execution_count": 5071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ1.shape, ddZ1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 64), (16, 64), (2, 16), (2, 16))"
      ]
     },
     "execution_count": 5072,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddweight2.shape, dweight2.shape, ddbias2.shape, dbias2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 16), (16, 64))"
      ]
     },
     "execution_count": 5073,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddecoded.shape, dweight2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 16), (16, 16))"
      ]
     },
     "execution_count": 5074,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfZ1.shape,fweight1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 16), (16, 16))"
      ]
     },
     "execution_count": 5075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfweight1.shape, fweight1.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (tags/v3.11.5:cce6ba9, Aug 24 2023, 14:38:34) [MSC v.1936 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "073d145d965d36c3210290915cf8a1d969510ed4ca01539e056264499c6101ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
